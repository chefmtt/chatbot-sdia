{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Our first approach is to generate, by hand, a simple collections of sentences organised by intents and associated answers.\n",
    "We will then process that data to make it suitable for NLP applications, encode it using \"bag of word\" and train a neural network to predict user intent from an utterance.\n",
    "\n",
    "Then, we wil used pre-trained word embeddings\n",
    "\n",
    "Then, we will generate training data using OpenAI GPT-3 API and train it, using both bag of words and word embeddings\n",
    "We can also try TF-IDF to compare it with the NN."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "A chatbot needs to understand intents in users' utterances. For this purpose, we train a classifier."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "I use the IMDB review dataset for basic testing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Import / Generate data\n",
    "\n",
    "In this section, we import our dataset, made of hand-crafted sentences and the corresponding intent."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import tree, svm, naive_bayes\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "import sklearn.metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from pprint import pprint\n",
    "from time import time\n",
    "from collections import defaultdict\n",
    "import spacy\n",
    "from spacy.tokens import DocBin\n",
    "nlp = spacy.load(\"en_core_web_lg\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "data_file = open('intents.json').read()\n",
    "intents = json.loads(data_file)\n",
    "\n",
    "\n",
    "data = []\n",
    "for intent in intents['intents']:\n",
    "    for pattern in intent['patterns']:\n",
    "        data.append([pattern, intent['tag']])\n",
    "\n",
    "df_json = pd.DataFrame(data, columns=['text','intent'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "df_csv = pd.read_csv(\"sentences/full.csv\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "                               text     intent\n0                                Hi   greeting\n1                               Hey   greeting\n2                 Is anyone there ?   greeting\n3                             Hello   greeting\n4                    Good morning !   greeting\n..                              ...        ...\n240        Thank you for your care.  gratitude\n241  Thank you for being my friend.  gratitude\n242       Thank you for everything.  gratitude\n243               You are the best!  gratitude\n244        I really appreciate you!  gratitude\n\n[277 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>intent</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Hi</td>\n      <td>greeting</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Hey</td>\n      <td>greeting</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Is anyone there ?</td>\n      <td>greeting</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Hello</td>\n      <td>greeting</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Good morning !</td>\n      <td>greeting</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>240</th>\n      <td>Thank you for your care.</td>\n      <td>gratitude</td>\n    </tr>\n    <tr>\n      <th>241</th>\n      <td>Thank you for being my friend.</td>\n      <td>gratitude</td>\n    </tr>\n    <tr>\n      <th>242</th>\n      <td>Thank you for everything.</td>\n      <td>gratitude</td>\n    </tr>\n    <tr>\n      <th>243</th>\n      <td>You are the best!</td>\n      <td>gratitude</td>\n    </tr>\n    <tr>\n      <th>244</th>\n      <td>I really appreciate you!</td>\n      <td>gratitude</td>\n    </tr>\n  </tbody>\n</table>\n<p>277 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([df_json, df_csv], axis=0)\n",
    "df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1530\n"
     ]
    }
   ],
   "source": [
    "print(df['text'].apply(lambda x: len(x.split(' '))).sum())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 1000x400 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10,4))\n",
    "df.intent.value_counts().plot(kind='bar');"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The intents that we want the chatbot to recognize are :"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "array(['greeting', 'goodbye', 'gratitude', 'about', 'help',\n       'printing_request', 'complaint', 'check_schedule'], dtype=object)"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"intent\"].unique()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data pre-processing\n",
    "\n",
    "In this section, we define functions to preprocess our text (parse it using a SpaCy pipeline) and to process it (extract tokens, lemmas or embeddings depending on the application).\n",
    "We save the preprocessed data to disk to avoid repeating this computationally expensive task."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# fine-tune preprocessing for spaCy word embeddings using this method : https://www.kaggle.com/code/christofhenkel/how-to-preprocessing-when-using-embeddings"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "\n",
    "def lemmatize_text(text, preprocessed=True):\n",
    "    return process_text(text, \"lemmatize\", preprocessed)\n",
    "\n",
    "def tokenize_text(text, preprocessed=True):\n",
    "    return process_text(text, \"tokenize\", preprocessed)\n",
    "\n",
    "def process_text(text, mode: str, preprocessed=True):\n",
    "    if not preprocessed:\n",
    "        text = nlp(text)\n",
    "    if mode == \"tokenize\":\n",
    "        processed_text = [token.text for token in text] # token and embed must have the same processing + SpaCy provides embeddings for punctuation\n",
    "    elif mode == \"embed\":\n",
    "        processed_text = [token.vector for token in text] # token and embed must have the same processing\n",
    "    elif mode == \"lemmatize\":\n",
    "        processed_text = [token.lemma_ for token in text\n",
    "                               if not token.is_punct and not token.is_space and not token.like_url and not token.like_email]\n",
    "    else:\n",
    "        raise ValueError(\"Mode not supported\")\n",
    "    return processed_text\n",
    "\n",
    "def save_preprocessed(raw_text, save_path):\n",
    "    doc_bin = DocBin(attrs=[\"LEMMA\", \"ENT_IOB\", \"ENT_TYPE\"], store_user_data=True)\n",
    "    for doc in nlp.pipe(raw_text):\n",
    "        doc_bin.add(doc)\n",
    "    # save DocBin to a file on disc\n",
    "    doc_bin.to_disk(save_path)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "file_name_spacy = 'preprocessed_dataset_chatbot.spacy'\n",
    "save_preprocessed(raw_text=df[\"text\"], save_path=file_name_spacy)\n",
    "\n",
    "# Load DocBin at later time or on different system from disc or bytes object\n",
    "doc_bin = DocBin().from_disk(file_name_spacy)\n",
    "df[\"doc\"] = list(doc_bin.get_docs(nlp.vocab))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "                               text     intent  \\\n0                                Hi   greeting   \n1                               Hey   greeting   \n2                 Is anyone there ?   greeting   \n3                             Hello   greeting   \n4                    Good morning !   greeting   \n..                              ...        ...   \n240        Thank you for your care.  gratitude   \n241  Thank you for being my friend.  gratitude   \n242       Thank you for everything.  gratitude   \n243               You are the best!  gratitude   \n244        I really appreciate you!  gratitude   \n\n                                         doc  \n0                                       (Hi)  \n1                                      (Hey)  \n2                     (Is, anyone, there, ?)  \n3                                    (Hello)  \n4                         (Good, morning, !)  \n..                                       ...  \n240         (Thank, you, for, your, care, .)  \n241  (Thank, you, for, being, my, friend, .)  \n242         (Thank, you, for, everything, .)  \n243                 (You, are, the, best, !)  \n244          (I, really, appreciate, you, !)  \n\n[277 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>intent</th>\n      <th>doc</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Hi</td>\n      <td>greeting</td>\n      <td>(Hi)</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Hey</td>\n      <td>greeting</td>\n      <td>(Hey)</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Is anyone there ?</td>\n      <td>greeting</td>\n      <td>(Is, anyone, there, ?)</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Hello</td>\n      <td>greeting</td>\n      <td>(Hello)</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Good morning !</td>\n      <td>greeting</td>\n      <td>(Good, morning, !)</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>240</th>\n      <td>Thank you for your care.</td>\n      <td>gratitude</td>\n      <td>(Thank, you, for, your, care, .)</td>\n    </tr>\n    <tr>\n      <th>241</th>\n      <td>Thank you for being my friend.</td>\n      <td>gratitude</td>\n      <td>(Thank, you, for, being, my, friend, .)</td>\n    </tr>\n    <tr>\n      <th>242</th>\n      <td>Thank you for everything.</td>\n      <td>gratitude</td>\n      <td>(Thank, you, for, everything, .)</td>\n    </tr>\n    <tr>\n      <th>243</th>\n      <td>You are the best!</td>\n      <td>gratitude</td>\n      <td>(You, are, the, best, !)</td>\n    </tr>\n    <tr>\n      <th>244</th>\n      <td>I really appreciate you!</td>\n      <td>gratitude</td>\n      <td>(I, really, appreciate, you, !)</td>\n    </tr>\n  </tbody>\n</table>\n<p>277 rows × 3 columns</p>\n</div>"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data preparation\n",
    "\n",
    "In this section, we create different training datasets, processing them using SpaCy and our helper functions :\n",
    "\n",
    "- `X_train` is a pandas Series made of all preprocessed sentence\n",
    "- `X_train_embedded` pandas Series, each sentence is a list of embeddings\n",
    "- `X_train_embedded_avg` panda Series, each sentence is the average of each of its words' embedding (using the sum would give embeddings of different magnitude depending of the sentence's length)\n",
    "- `X_train_embedded_avg_tfidf` The previous average is weighted using TF-IDF coefficient (trained on ngrams of 1 token)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [],
   "source": [
    "train, test = train_test_split(df, test_size=0.3)\n",
    "\n",
    "X_train = train[\"doc\"].reset_index(drop=True)\n",
    "y_train = train[\"intent\"].reset_index(drop=True)\n",
    "\n",
    "X_test = test[\"doc\"].reset_index(drop=True)\n",
    "y_test = test[\"intent\"].reset_index(drop=True)\n",
    "\n",
    "X_train_embedded = train[\"doc\"].apply(process_text, args=(\"embed\", True,))\n",
    "X_train_embedded_avg = X_train_embedded.apply(np.mean, axis=0).apply(pd.Series)\n",
    "\n",
    "X_test_embedded = test[\"doc\"].apply(process_text, args=(\"embed\", True,))\n",
    "X_test_embedded_avg = X_test_embedded.apply(np.mean, axis=0).apply(pd.Series)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# The following code block construct a sentence representation as the average of all embeddings of the words in it, weighted by their tfidf score\n",
    "# This is not practical in our chatbot : using word embeddings is one way of mitigating the small dataset size, as words close in meaning should have similar embeddings\n",
    "# Weighing by tf-idf score would \"delete\" unknown world from the vocabulary, which we do not want\n",
    "\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1, 1), lowercase=False, tokenizer=tokenize_text, max_features=10000)\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train) # Maybe not ? Bias, vocab for test in vect // But that would be dumb to not use the vocab for the final one // BEST : Only do vocab on X_train, but if tfidf selected train final on FULL dataset\n",
    "weighted_averages = []\n",
    "for (idxRow, sentence) in X_train.items():\n",
    "    sum_embeddings = 0\n",
    "    for idxWord, word in enumerate(sentence):\n",
    "        try:\n",
    "            tfidf_idx = vectorizer.vocabulary_[word]\n",
    "        except(KeyError):\n",
    "            continue\n",
    "        sum_embeddings += (X_train_tfidf.toarray())[idxRow][tfidf_idx] * X_train_embedded.iloc[idxRow][idxWord]\n",
    "    weighted_averages.append(sum_embeddings/len(sentence))\n",
    "\n",
    "X_train_embedded_avg_tfidf = pd.Series(weighted_averages).apply(pd.Series)\n",
    "\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "weighted_averages = []\n",
    "for (idxRow, sentence) in X_test.items():\n",
    "    sum_embeddings = 0\n",
    "    for idxWord, word in enumerate(sentence):\n",
    "        try:\n",
    "            tfidf_idx = vectorizer.vocabulary_[word]\n",
    "        except(KeyError):\n",
    "            continue\n",
    "        sum_embeddings += (X_test_tfidf.toarray())[idxRow][tfidf_idx] * X_test_embedded.iloc[idxRow][idxWord]\n",
    "    weighted_averages.append(sum_embeddings/len(sentence))\n",
    "\n",
    "X_test_embedded_avg_tfidf = pd.Series(weighted_averages).apply(pd.Series)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "TODO : Explain alternatives (sense2vec, Doc2vec)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Classic ML\n",
    "\n",
    "Our first approach to create our classifier is to use traditional ML algorithms.\n",
    "\n",
    "We will use several algorithms and 3 different approach to represent our training data :\n",
    "\n",
    "- A classic TF-IDF representation (with or without IDF, which is equivalent to a bag-of-words approach)\n",
    "- A \"sentence2vec\" (or s2v) approach, where a sentence is the average of its words' embedding.\n",
    "- A TF-IDF weighted average of word embeddings, s2v_tfidf"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Models preparation\n",
    "\n",
    "We use the sklearn implementation of GridSearchCV, which optimises the parameters of an estimator (here, our classifiers) by cross-validated grid-search over a parameter grid.\n",
    "We select different algorithms, define a pipeline and a set of parameters for each of those.\n",
    "The use of the pipeline allows us to select the best parameters for the TF-IDF vectorization.\n",
    "\n",
    "The size of our dataset does not contrains us in the choice of the algorithm, as training time is not a concern (No need to swap SVC for LinearSVC or SGDClassifier, for example)\n",
    "\n",
    "GridSearchCV uses K-fold as the cross-validation method. Here, we used 5-fold stratified K-fold.\n",
    "\n",
    "List parameters for clf and vectorizer ?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Below are defined the models and their corresponding hyperparameters to tune for the TF-IDF approach"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "vect = TfidfVectorizer(lowercase=False, tokenizer=lemmatize_text, max_features=3000)\n",
    "\n",
    "gs_dict_tfidf = defaultdict(dict)\n",
    "\n",
    "dectree = tree.DecisionTreeClassifier() # CART\n",
    "svm_clf = svm.SVC()\n",
    "multi_nb = naive_bayes.MultinomialNB() # Not suitable for negative values (thus not suitable for word embeddings)\n",
    "log_reg = LogisticRegression()\n",
    "random_forest = RandomForestClassifier()\n",
    "skboost = GradientBoostingClassifier()\n",
    "\n",
    "gs_dict_tfidf['dectree']['pipeline'] = Pipeline([\n",
    "    ('vect', vect),\n",
    "    ('dectree', dectree)])\n",
    "gs_dict_tfidf['svm_clf']['pipeline'] = Pipeline([\n",
    "    ('vect', vect),\n",
    "    ('svm_clf', svm_clf)])\n",
    "gs_dict_tfidf['multi_nb']['pipeline'] = Pipeline([\n",
    "    ('vect', vect),\n",
    "    ('multi_nb', multi_nb)])\n",
    "gs_dict_tfidf['log_reg']['pipeline'] = Pipeline([\n",
    "    ('vect', vect),\n",
    "    ('log_reg', log_reg)])\n",
    "gs_dict_tfidf['random_forest']['pipeline'] = Pipeline([\n",
    "    ('vect', vect),\n",
    "    ('random_forest', random_forest)])\n",
    "gs_dict_tfidf['skboost']['pipeline'] = Pipeline([\n",
    "    ('vect', vect),\n",
    "    ('skboost', skboost)])\n",
    "\n",
    "gs_dict_tfidf['dectree']['params'] = {\n",
    "    \"dectree__max_depth\": [4, 40],\n",
    "    \"vect__ngram_range\": ((1, 1), (1, 2), (1,3), (1,4)),\n",
    "    \"vect__use_idf\": (True, False),\n",
    "    \"vect__binary\": (True, False),\n",
    "}\n",
    "gs_dict_tfidf['svm_clf']['params'] = {\n",
    "    \"svm_clf__kernel\": [\"linear\", \"rbf\"],\n",
    "    \"vect__ngram_range\": ((1, 1), (1, 2), (1,3), (1,4)),\n",
    "    \"vect__use_idf\": (True, False),\n",
    "    \"vect__binary\": (True, False),\n",
    "}\n",
    "gs_dict_tfidf['multi_nb']['params'] = {\n",
    "    \"multi_nb__alpha\": [0.00001, 0.0001, 0.001, 0.1, 1, 10, 100,1000],\n",
    "    \"vect__ngram_range\": ((1, 1), (1, 2), (1,3), (1,4)),\n",
    "    \"vect__use_idf\": (True, False),\n",
    "    \"vect__binary\": (True, False),\n",
    "}\n",
    "gs_dict_tfidf['log_reg']['params'] = {\n",
    "    \"vect__ngram_range\": ((1, 1), (1, 2), (1,3), (1,4)),\n",
    "    \"vect__use_idf\": (True, False),\n",
    "    \"vect__binary\": (True, False),\n",
    "}\n",
    "gs_dict_tfidf['random_forest']['params'] = {\n",
    "    \"vect__ngram_range\": ((1, 1), (1, 2), (1,3), (1,4)),\n",
    "    \"vect__use_idf\": (True, False),\n",
    "    \"vect__binary\": (True, False),\n",
    "}\n",
    "gs_dict_tfidf['skboost']['params'] = {\n",
    "    \"vect__ngram_range\": ((1, 1), (1, 2), (1,3), (1,4)),\n",
    "    \"vect__use_idf\": (True, False),\n",
    "    \"vect__binary\": (True, False),\n",
    "}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Below are defined the models to be used with the two embeddings approaches"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "gs_dict_embeddings = defaultdict(dict)\n",
    "# classifiers to use\n",
    "dectree = tree.DecisionTreeClassifier()\n",
    "svm_clf = svm.SVC()\n",
    "\n",
    "gs_dict_embeddings['dectree']['pipeline'] = Pipeline([\n",
    "    ('dectree', dectree)])\n",
    "gs_dict_embeddings['svm_clf']['pipeline'] = Pipeline([\n",
    "    ('svm_clf', svm_clf)])\n",
    "gs_dict_embeddings['log_reg']['pipeline'] = Pipeline([\n",
    "    ('log_reg', log_reg)])\n",
    "gs_dict_embeddings['random_forest']['pipeline'] = Pipeline([\n",
    "    ('random_forest', random_forest)])\n",
    "gs_dict_embeddings['skboost']['pipeline'] = Pipeline([\n",
    "    ('skboost', skboost)])\n",
    "\n",
    "gs_dict_embeddings['dectree']['params'] = {\n",
    "    \"dectree__max_depth\": [4, 10],\n",
    "}\n",
    "gs_dict_embeddings['svm_clf']['params'] = {\n",
    "    \"svm_clf__kernel\": [\"linear\", \"rbf\"],\n",
    "}\n",
    "gs_dict_embeddings['log_reg']['params'] = {\n",
    "\n",
    "}\n",
    "gs_dict_embeddings['random_forest']['params'] = {\n",
    "\n",
    "}\n",
    "gs_dict_embeddings['skboost']['params'] = {\n",
    "\n",
    "}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model Selection"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "\n",
    "def perform_grid_search(X_train, y_train, pipeline, parameters, scoring):\n",
    "    gs_clf = GridSearchCV(pipeline, parameters, n_jobs=1, verbose=1, cv=3, scoring=scoring) # Issue when n_jobs = -1 OR > 1\n",
    "    # I believe this may be because we use a custom tokenizer in TfidfVectorizer(), can't find how to solve it\n",
    "    print(\"\\n------------------------------------------------------------------------\\n\")\n",
    "    print(\"pipeline:\", [name for name, _ in pipeline.steps])\n",
    "    print(\"parameters:\")\n",
    "    pprint(parameters)\n",
    "\n",
    "    t0 = time()\n",
    "\n",
    "    gs_clf.fit(X_train, y_train)\n",
    "\n",
    "    print(\"\\nDone in %0.3fs\" % (time() - t0))\n",
    "    print()\n",
    "\n",
    "    print(\"Best score: %0.3f\" % gs_clf.best_score_)\n",
    "    print(\"Best parameters set:\")\n",
    "    best_parameters = gs_clf.best_estimator_.get_params()\n",
    "    for param_name in sorted(parameters.keys()):\n",
    "        print(f\"\\t'{param_name}': '{best_parameters[param_name]}'\")\n",
    "    return gs_clf\n",
    "\n",
    "def best_estimator_per_clf(X_train, y_train, gs_dict: defaultdict, scoring):\n",
    "    for clf in dict(gs_dict):\n",
    "        gs_dict[clf]['gs'] = perform_grid_search(\n",
    "            X_train,\n",
    "            y_train,\n",
    "            gs_dict[clf]['pipeline'],\n",
    "            gs_dict[clf]['params'],\n",
    "            scoring\n",
    "        )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "pipeline: ['vect', 'dectree']\n",
      "parameters:\n",
      "{'dectree__max_depth': [4, 40],\n",
      " 'vect__binary': (True, False),\n",
      " 'vect__ngram_range': ((1, 1), (1, 2), (1, 3), (1, 4)),\n",
      " 'vect__use_idf': (True, False)}\n",
      "Fitting 3 folds for each of 32 candidates, totalling 96 fits\n",
      "\n",
      "Done in 0.584s\n",
      "\n",
      "Best score: 0.777\n",
      "Best parameters set:\n",
      "\t'dectree__max_depth': '40'\n",
      "\t'vect__binary': 'False'\n",
      "\t'vect__ngram_range': '(1, 2)'\n",
      "\t'vect__use_idf': 'True'\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "pipeline: ['vect', 'svm_clf']\n",
      "parameters:\n",
      "{'svm_clf__kernel': ['linear', 'rbf'],\n",
      " 'vect__binary': (True, False),\n",
      " 'vect__ngram_range': ((1, 1), (1, 2), (1, 3), (1, 4)),\n",
      " 'vect__use_idf': (True, False)}\n",
      "Fitting 3 folds for each of 32 candidates, totalling 96 fits\n",
      "\n",
      "Done in 1.129s\n",
      "\n",
      "Best score: 0.839\n",
      "Best parameters set:\n",
      "\t'svm_clf__kernel': 'linear'\n",
      "\t'vect__binary': 'True'\n",
      "\t'vect__ngram_range': '(1, 2)'\n",
      "\t'vect__use_idf': 'True'\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "pipeline: ['vect', 'multi_nb']\n",
      "parameters:\n",
      "{'multi_nb__alpha': [1e-05, 0.0001, 0.001, 0.1, 1, 10, 100, 1000],\n",
      " 'vect__binary': (True, False),\n",
      " 'vect__ngram_range': ((1, 1), (1, 2), (1, 3), (1, 4)),\n",
      " 'vect__use_idf': (True, False)}\n",
      "Fitting 3 folds for each of 128 candidates, totalling 384 fits\n",
      "\n",
      "Done in 2.059s\n",
      "\n",
      "Best score: 0.787\n",
      "Best parameters set:\n",
      "\t'multi_nb__alpha': '1e-05'\n",
      "\t'vect__binary': 'True'\n",
      "\t'vect__ngram_range': '(1, 2)'\n",
      "\t'vect__use_idf': 'True'\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "pipeline: ['vect', 'log_reg']\n",
      "parameters:\n",
      "{'vect__binary': (True, False),\n",
      " 'vect__ngram_range': ((1, 1), (1, 2), (1, 3), (1, 4)),\n",
      " 'vect__use_idf': (True, False)}\n",
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n",
      "\n",
      "Done in 1.163s\n",
      "\n",
      "Best score: 0.824\n",
      "Best parameters set:\n",
      "\t'vect__binary': 'True'\n",
      "\t'vect__ngram_range': '(1, 2)'\n",
      "\t'vect__use_idf': 'False'\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "pipeline: ['vect', 'random_forest']\n",
      "parameters:\n",
      "{'vect__binary': (True, False),\n",
      " 'vect__ngram_range': ((1, 1), (1, 2), (1, 3), (1, 4)),\n",
      " 'vect__use_idf': (True, False)}\n",
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n",
      "\n",
      "Done in 5.219s\n",
      "\n",
      "Best score: 0.839\n",
      "Best parameters set:\n",
      "\t'vect__binary': 'True'\n",
      "\t'vect__ngram_range': '(1, 2)'\n",
      "\t'vect__use_idf': 'True'\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "pipeline: ['vect', 'skboost']\n",
      "parameters:\n",
      "{'vect__binary': (True, False),\n",
      " 'vect__ngram_range': ((1, 1), (1, 2), (1, 3), (1, 4)),\n",
      " 'vect__use_idf': (True, False)}\n",
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n",
      "\n",
      "Done in 31.772s\n",
      "\n",
      "Best score: 0.829\n",
      "Best parameters set:\n",
      "\t'vect__binary': 'True'\n",
      "\t'vect__ngram_range': '(1, 3)'\n",
      "\t'vect__use_idf': 'False'\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "pipeline: ['dectree']\n",
      "parameters:\n",
      "{'dectree__max_depth': [4, 10]}\n",
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
      "\n",
      "Done in 0.114s\n",
      "\n",
      "Best score: 0.611\n",
      "Best parameters set:\n",
      "\t'dectree__max_depth': '10'\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "pipeline: ['svm_clf']\n",
      "parameters:\n",
      "{'svm_clf__kernel': ['linear', 'rbf']}\n",
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
      "\n",
      "Done in 0.053s\n",
      "\n",
      "Best score: 0.886\n",
      "Best parameters set:\n",
      "\t'svm_clf__kernel': 'linear'\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "pipeline: ['log_reg']\n",
      "parameters:\n",
      "{}\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matthieu/miniconda3/envs/chatbot-sdia/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/matthieu/miniconda3/envs/chatbot-sdia/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/matthieu/miniconda3/envs/chatbot-sdia/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/matthieu/miniconda3/envs/chatbot-sdia/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done in 0.165s\n",
      "\n",
      "Best score: 0.875\n",
      "Best parameters set:\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "pipeline: ['random_forest']\n",
      "parameters:\n",
      "{}\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "\n",
      "Done in 0.588s\n",
      "\n",
      "Best score: 0.855\n",
      "Best parameters set:\n",
      "\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "pipeline: ['skboost']\n",
      "parameters:\n",
      "{}\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "\n",
      "Done in 21.703s\n",
      "\n",
      "Best score: 0.699\n",
      "Best parameters set:\n"
     ]
    }
   ],
   "source": [
    "best_estimator_per_clf(X_train, y_train, gs_dict_tfidf, scoring=\"accuracy\")\n",
    "best_estimator_per_clf(X_train_embedded_avg, y_train, gs_dict_embeddings, scoring=\"accuracy\")\n",
    "\n",
    "# TODO : Use random state in gsCV and XGBoost for reporductibility\n",
    "\n",
    "# TODO : implement multiple scoring : https://scikit-learn.org/stable/auto_examples/model_selection/plot_multi_metric_evaluation.html#sphx-glr-auto-examples-model-selection-plot-multi-metric-evaluation-py\n",
    "\n",
    "# TODO : extract metrics https://scikit-learn.org/stable/auto_examples/model_selection/plot_multi_metric_evaluation.html#sphx-glr-auto-examples-model-selection-plot-multi-metric-evaluation-py"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------\n",
      "TF-IDF\n",
      "dectree - TF-IDF\n",
      "\n",
      "accuracy 0.9166666666666666\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "           about       1.00      0.82      0.90        11\n",
      "  check_schedule       1.00      1.00      1.00         6\n",
      "       complaint       0.92      1.00      0.96        11\n",
      "         goodbye       0.86      1.00      0.92        12\n",
      "       gratitude       1.00      0.94      0.97        18\n",
      "        greeting       0.67      0.75      0.71         8\n",
      "            help       0.88      0.88      0.88         8\n",
      "printing_request       1.00      0.90      0.95        10\n",
      "\n",
      "        accuracy                           0.92        84\n",
      "       macro avg       0.91      0.91      0.91        84\n",
      "    weighted avg       0.93      0.92      0.92        84\n",
      "\n",
      "---------------------------------------------------------\n",
      "svm_clf - TF-IDF\n",
      "\n",
      "accuracy 0.9523809523809523\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "           about       1.00      1.00      1.00        11\n",
      "  check_schedule       1.00      1.00      1.00         6\n",
      "       complaint       1.00      1.00      1.00        11\n",
      "         goodbye       0.86      1.00      0.92        12\n",
      "       gratitude       1.00      0.94      0.97        18\n",
      "        greeting       0.86      0.75      0.80         8\n",
      "            help       0.89      1.00      0.94         8\n",
      "printing_request       1.00      0.90      0.95        10\n",
      "\n",
      "        accuracy                           0.95        84\n",
      "       macro avg       0.95      0.95      0.95        84\n",
      "    weighted avg       0.96      0.95      0.95        84\n",
      "\n",
      "---------------------------------------------------------\n",
      "multi_nb - TF-IDF\n",
      "\n",
      "accuracy 0.9523809523809523\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "           about       0.92      1.00      0.96        11\n",
      "  check_schedule       1.00      1.00      1.00         6\n",
      "       complaint       0.92      1.00      0.96        11\n",
      "         goodbye       0.92      0.92      0.92        12\n",
      "       gratitude       1.00      0.94      0.97        18\n",
      "        greeting       0.88      0.88      0.88         8\n",
      "            help       1.00      1.00      1.00         8\n",
      "printing_request       1.00      0.90      0.95        10\n",
      "\n",
      "        accuracy                           0.95        84\n",
      "       macro avg       0.95      0.95      0.95        84\n",
      "    weighted avg       0.95      0.95      0.95        84\n",
      "\n",
      "---------------------------------------------------------\n",
      "log_reg - TF-IDF\n",
      "\n",
      "accuracy 0.8809523809523809\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "           about       1.00      1.00      1.00        11\n",
      "  check_schedule       1.00      1.00      1.00         6\n",
      "       complaint       0.65      1.00      0.79        11\n",
      "         goodbye       0.86      1.00      0.92        12\n",
      "       gratitude       1.00      0.94      0.97        18\n",
      "        greeting       0.83      0.62      0.71         8\n",
      "            help       0.80      0.50      0.62         8\n",
      "printing_request       1.00      0.80      0.89        10\n",
      "\n",
      "        accuracy                           0.88        84\n",
      "       macro avg       0.89      0.86      0.86        84\n",
      "    weighted avg       0.90      0.88      0.88        84\n",
      "\n",
      "---------------------------------------------------------\n",
      "random_forest - TF-IDF\n",
      "\n",
      "accuracy 0.9285714285714286\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "           about       1.00      1.00      1.00        11\n",
      "  check_schedule       1.00      1.00      1.00         6\n",
      "       complaint       0.85      1.00      0.92        11\n",
      "         goodbye       0.86      1.00      0.92        12\n",
      "       gratitude       1.00      0.94      0.97        18\n",
      "        greeting       0.86      0.75      0.80         8\n",
      "            help       0.86      0.75      0.80         8\n",
      "printing_request       1.00      0.90      0.95        10\n",
      "\n",
      "        accuracy                           0.93        84\n",
      "       macro avg       0.93      0.92      0.92        84\n",
      "    weighted avg       0.93      0.93      0.93        84\n",
      "\n",
      "---------------------------------------------------------\n",
      "skboost - TF-IDF\n",
      "\n",
      "accuracy 0.9404761904761905\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "           about       1.00      1.00      1.00        11\n",
      "  check_schedule       1.00      1.00      1.00         6\n",
      "       complaint       1.00      1.00      1.00        11\n",
      "         goodbye       0.86      1.00      0.92        12\n",
      "       gratitude       1.00      0.89      0.94        18\n",
      "        greeting       0.86      0.75      0.80         8\n",
      "            help       0.80      1.00      0.89         8\n",
      "printing_request       1.00      0.90      0.95        10\n",
      "\n",
      "        accuracy                           0.94        84\n",
      "       macro avg       0.94      0.94      0.94        84\n",
      "    weighted avg       0.95      0.94      0.94        84\n",
      "\n",
      "---------------------------------------------------------\n",
      "\n",
      "EMBEDDINGS AVERAGED\n",
      "\n",
      "---------------------------------------------------------\n",
      "dectree - Embeddings averaged\n",
      "\n",
      "accuracy 0.9404761904761905\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "           about       1.00      0.91      0.95        11\n",
      "  check_schedule       1.00      1.00      1.00         6\n",
      "       complaint       0.92      1.00      0.96        11\n",
      "         goodbye       1.00      1.00      1.00        12\n",
      "       gratitude       0.85      0.94      0.89        18\n",
      "        greeting       1.00      0.88      0.93         8\n",
      "            help       0.86      0.75      0.80         8\n",
      "printing_request       1.00      1.00      1.00        10\n",
      "\n",
      "        accuracy                           0.94        84\n",
      "       macro avg       0.95      0.93      0.94        84\n",
      "    weighted avg       0.94      0.94      0.94        84\n",
      "\n",
      "---------------------------------------------------------\n",
      "svm_clf - Embeddings averaged\n",
      "\n",
      "accuracy 0.9642857142857143\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "           about       0.92      1.00      0.96        11\n",
      "  check_schedule       1.00      1.00      1.00         6\n",
      "       complaint       1.00      1.00      1.00        11\n",
      "         goodbye       0.92      1.00      0.96        12\n",
      "       gratitude       1.00      0.94      0.97        18\n",
      "        greeting       0.88      0.88      0.88         8\n",
      "            help       1.00      1.00      1.00         8\n",
      "printing_request       1.00      0.90      0.95        10\n",
      "\n",
      "        accuracy                           0.96        84\n",
      "       macro avg       0.96      0.96      0.96        84\n",
      "    weighted avg       0.97      0.96      0.96        84\n",
      "\n",
      "---------------------------------------------------------\n",
      "log_reg - Embeddings averaged\n",
      "\n",
      "accuracy 0.9523809523809523\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "           about       0.92      1.00      0.96        11\n",
      "  check_schedule       1.00      1.00      1.00         6\n",
      "       complaint       0.92      1.00      0.96        11\n",
      "         goodbye       0.92      1.00      0.96        12\n",
      "       gratitude       1.00      0.94      0.97        18\n",
      "        greeting       0.86      0.75      0.80         8\n",
      "            help       1.00      0.88      0.93         8\n",
      "printing_request       1.00      1.00      1.00        10\n",
      "\n",
      "        accuracy                           0.95        84\n",
      "       macro avg       0.95      0.95      0.95        84\n",
      "    weighted avg       0.95      0.95      0.95        84\n",
      "\n",
      "---------------------------------------------------------\n",
      "random_forest - Embeddings averaged\n",
      "\n",
      "accuracy 0.9761904761904762\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "           about       1.00      1.00      1.00        11\n",
      "  check_schedule       1.00      1.00      1.00         6\n",
      "       complaint       1.00      1.00      1.00        11\n",
      "         goodbye       0.92      1.00      0.96        12\n",
      "       gratitude       1.00      1.00      1.00        18\n",
      "        greeting       1.00      0.88      0.93         8\n",
      "            help       0.89      1.00      0.94         8\n",
      "printing_request       1.00      0.90      0.95        10\n",
      "\n",
      "        accuracy                           0.98        84\n",
      "       macro avg       0.98      0.97      0.97        84\n",
      "    weighted avg       0.98      0.98      0.98        84\n",
      "\n",
      "---------------------------------------------------------\n",
      "skboost - Embeddings averaged\n",
      "\n",
      "accuracy 0.9523809523809523\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "           about       1.00      1.00      1.00        11\n",
      "  check_schedule       1.00      1.00      1.00         6\n",
      "       complaint       0.92      1.00      0.96        11\n",
      "         goodbye       1.00      0.92      0.96        12\n",
      "       gratitude       1.00      0.94      0.97        18\n",
      "        greeting       0.70      0.88      0.78         8\n",
      "            help       1.00      1.00      1.00         8\n",
      "printing_request       1.00      0.90      0.95        10\n",
      "\n",
      "        accuracy                           0.95        84\n",
      "       macro avg       0.95      0.95      0.95        84\n",
      "    weighted avg       0.96      0.95      0.95        84\n",
      "\n",
      "---------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "print(\"---------------------------------------------------------\")\n",
    "print(\"TF-IDF\")\n",
    "for clf in dict(gs_dict_tfidf):\n",
    "    print(f\"{clf} - TF-IDF\\n\")\n",
    "    y_pred = gs_dict_tfidf[clf]['gs'].predict(X_test)\n",
    "\n",
    "    print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(\"---------------------------------------------------------\")\n",
    "print(\"\\nEMBEDDINGS AVERAGED\")\n",
    "print(\"\\n---------------------------------------------------------\")\n",
    "\n",
    "for clf in dict(gs_dict_embeddings):\n",
    "    print(f\"{clf} - Embeddings averaged\\n\")\n",
    "    y_pred = gs_dict_embeddings[clf]['gs'].predict(X_test_embedded_avg)\n",
    "\n",
    "    print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(\"---------------------------------------------------------\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "best_estimator_per_clf(X_train_embedded_avg, y_train, gs_dict_embeddings, scoring=\"accuracy\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test = sum(process_text(nlp(\"I want to print 76 page of a document\"), mode=\"embed\"))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = gs_dict_embeddings['svm_clf']['gs'].best_estimator_\n",
    "model.predict([test])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Neural networks"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model preparation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model selection"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "idea : skew text classification if name entities are found (either by multiple channels NN or by adding a feature to the data passed)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "data": {
      "text/plain": "684830"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LSTM : https://www.tensorflow.org/text/tutorials/text_classification_rnn\n",
    "len(nlp.vocab.vectors.keys())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "max_words = 30 # Max number of words in a sentence\n",
    "\n",
    "raw_inputs = X_train_embedded\n",
    "padded_inputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "    X_train_embedded,\n",
    "    maxlen=max_words,\n",
    "    padding=\"pre\",\n",
    "    truncating=\"pre\",\n",
    "    dtype=\"float32\",\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "padded_inputs.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_42\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " masking_16 (Masking)        (None, None, 300)         0         \n",
      "                                                                 \n",
      " lstm_16 (LSTM)              (None, 128)               219648    \n",
      "                                                                 \n",
      " dense_68 (Dense)            (None, 8)                 1032      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 220,680\n",
      "Trainable params: 220,680\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "5/5 [==============================] - 5s 322ms/step - loss: 1.8995 - accuracy: 0.3630 - val_loss: 1.7495 - val_accuracy: 0.4655\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 0s 102ms/step - loss: 1.4867 - accuracy: 0.5778 - val_loss: 1.5193 - val_accuracy: 0.5172\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 0s 85ms/step - loss: 1.1592 - accuracy: 0.7037 - val_loss: 1.2608 - val_accuracy: 0.6207\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 1s 115ms/step - loss: 0.8748 - accuracy: 0.7630 - val_loss: 1.0526 - val_accuracy: 0.6552\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 1s 121ms/step - loss: 0.6739 - accuracy: 0.8074 - val_loss: 0.9024 - val_accuracy: 0.7241\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 1s 124ms/step - loss: 0.5349 - accuracy: 0.8519 - val_loss: 0.7787 - val_accuracy: 0.7759\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 1s 114ms/step - loss: 0.4115 - accuracy: 0.9185 - val_loss: 0.6877 - val_accuracy: 0.8793\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 1s 123ms/step - loss: 0.3211 - accuracy: 0.9630 - val_loss: 0.6158 - val_accuracy: 0.8966\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 0.2653 - accuracy: 0.9778 - val_loss: 0.5526 - val_accuracy: 0.8621\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 1s 101ms/step - loss: 0.2049 - accuracy: 0.9852 - val_loss: 0.5232 - val_accuracy: 0.8621\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense, Input, Masking\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y_train)\n",
    "number_classes = len(y_train.unique())\n",
    "\n",
    "model=Sequential()\n",
    "#model.add(Embedding(vocab_size,300,input_length=max_words))\n",
    "model.add(Masking(mask_value=0, input_shape=(None, 300)))\n",
    "model.add(LSTM(units=128,\n",
    "               return_sequences=False,\n",
    "               input_shape=(None, 300)\n",
    "               ))\n",
    "model.add(Dense(number_classes, activation='softmax'))\n",
    "\n",
    "print(model.summary())\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(tf.convert_to_tensor(padded_inputs), y_encoded, epochs=10, validation_split=0.3)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 26 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa65715bca0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "padded_test_inputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "    X_test_embedded,\n",
    "    maxlen=max_words,\n",
    "    padding=\"pre\",\n",
    "    truncating=\"pre\",\n",
    "    dtype=\"float32\",\n",
    ")\n",
    "y_pred = np.argmax(model.predict(tf.convert_to_tensor(padded_test_inputs)), axis=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 1s 58ms/step - loss: 0.3272 - accuracy: 0.8929\n"
     ]
    },
    {
     "data": {
      "text/plain": "[0.3271803557872772, 0.8928571343421936]"
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x=tf.convert_to_tensor(padded_test_inputs), y=le.transform(y_test))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "data": {
      "text/plain": "0.8928571428571429"
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(le.transform(y_test), y_pred)\n",
    "accuracy"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "data": {
      "text/plain": "array(['check_schedule'], dtype=object)"
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = process_text(\"I would like to see the planning\", mode=\"embed\", preprocessed=False)\n",
    "predict = model.predict(np.asarray([test]))\n",
    "predicted_class = np.argmax(predict)\n",
    "predicted_class = le.inverse_transform([predicted_class])\n",
    "predicted_class"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Makes no sense to train LSTM / CNN on Tf-Idf : They preserve spatial / temporal information, but that information is lost with tfidf\n",
    "# Does not play to their strength, not more relevant than a classic classifier"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Helper function\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_graphs(history, metric):\n",
    "  plt.plot(history.history[metric])\n",
    "  plt.plot(history.history['val_'+metric], '')\n",
    "  plt.xlabel(\"Epochs\")\n",
    "  plt.ylabel(metric)\n",
    "  plt.legend([metric, 'val_'+metric])\n",
    "\n",
    "plot_graphs(history, \"loss\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "5/5 [==============================] - 1s 78ms/step - loss: 1.9262 - accuracy: 0.2593 - val_loss: 1.8057 - val_accuracy: 0.1724\n",
      "Epoch 2/15\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.6478 - accuracy: 0.2741 - val_loss: 1.6941 - val_accuracy: 0.2759\n",
      "Epoch 3/15\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 1.5068 - accuracy: 0.3778 - val_loss: 1.6007 - val_accuracy: 0.3793\n",
      "Epoch 4/15\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 1.3877 - accuracy: 0.4741 - val_loss: 1.5015 - val_accuracy: 0.4310\n",
      "Epoch 5/15\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 1.2600 - accuracy: 0.5185 - val_loss: 1.4150 - val_accuracy: 0.5000\n",
      "Epoch 6/15\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 1.1433 - accuracy: 0.5852 - val_loss: 1.3247 - val_accuracy: 0.5345\n",
      "Epoch 7/15\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.0682 - accuracy: 0.6222 - val_loss: 1.2898 - val_accuracy: 0.5172\n",
      "Epoch 8/15\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 1.0043 - accuracy: 0.5852 - val_loss: 1.2700 - val_accuracy: 0.5345\n",
      "Epoch 9/15\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.9605 - accuracy: 0.6296 - val_loss: 1.2176 - val_accuracy: 0.5862\n",
      "Epoch 10/15\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.9075 - accuracy: 0.6444 - val_loss: 1.1895 - val_accuracy: 0.6034\n",
      "Epoch 11/15\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.8593 - accuracy: 0.6667 - val_loss: 1.1954 - val_accuracy: 0.5862\n",
      "Epoch 12/15\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.8242 - accuracy: 0.6741 - val_loss: 1.1559 - val_accuracy: 0.6207\n",
      "Epoch 13/15\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.7819 - accuracy: 0.7407 - val_loss: 1.0901 - val_accuracy: 0.6379\n",
      "Epoch 14/15\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.7477 - accuracy: 0.7556 - val_loss: 1.0799 - val_accuracy: 0.6552\n",
      "Epoch 15/15\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.7123 - accuracy: 0.7481 - val_loss: 1.0633 - val_accuracy: 0.6724\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "tf.keras.layers.Conv1D(64, 3, activation='relu'),\n",
    "tf.keras.layers.GlobalMaxPooling1D(),\n",
    "Dense(10, activation='relu'),\n",
    "Dense(number_classes, activation='softmax')])\n",
    "model.compile(loss='sparse_categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(tf.convert_to_tensor(padded_inputs), y_encoded, epochs=15, validation_split=0.3)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 17ms/step - loss: 1.2400 - accuracy: 0.5952\n"
     ]
    },
    {
     "data": {
      "text/plain": "[1.2400312423706055, 0.5952380895614624]"
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(padded_test_inputs, y=le.transform(y_test))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4528/114759089.py:15: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = tf.keras.wrappers.scikit_learn.KerasClassifier(build_fn=model_to_optimize,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 9 candidates, totalling 18 fits\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def model_to_optimize(num_filters, kernel_size):\n",
    "    model = Sequential([\n",
    "    tf.keras.layers.Conv1D(num_filters, kernel_size, activation='relu'),\n",
    "    tf.keras.layers.GlobalMaxPooling1D(),\n",
    "    Dense(10, activation='relu'),\n",
    "    Dense(number_classes, activation='softmax')])\n",
    "    model.compile(loss='sparse_categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "params = {\n",
    "    \"num_filters\":[32, 64, 128],\n",
    "    \"kernel_size\":[3, 5, 7],\n",
    "}\n",
    "\n",
    "model = tf.keras.wrappers.scikit_learn.KerasClassifier(build_fn=model_to_optimize,\n",
    "                            epochs=20,\n",
    "                           batch_size=10,\n",
    "                            verbose=False)\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "search = GridSearchCV(estimator=model, param_grid=params,\n",
    "                              cv=2, verbose=1)\n",
    "search_result = search.fit(padded_inputs, y_encoded)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [
    {
     "data": {
      "text/plain": "{'kernel_size': 3, 'num_filters': 64}"
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_result.best_params_"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [
    {
     "data": {
      "text/plain": "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n0       1.882793      0.454283         0.298693        0.015253   \n1       1.641088      0.024222         0.244344        0.042319   \n2       1.414505      0.022797         0.277051        0.042893   \n3       1.372716      0.237321         0.282250        0.001934   \n4       1.531836      0.135869         0.266720        0.014222   \n5       1.619876      0.008948         0.271923        0.003191   \n6       1.255499      0.045334         0.298526        0.054369   \n7       1.654373      0.025872         0.193702        0.041367   \n8       1.777422      0.034260         0.296066        0.010772   \n\n  param_kernel_size param_num_filters                                  params  \\\n0                 3                32   {'kernel_size': 3, 'num_filters': 32}   \n1                 3                64   {'kernel_size': 3, 'num_filters': 64}   \n2                 3               128  {'kernel_size': 3, 'num_filters': 128}   \n3                 5                32   {'kernel_size': 5, 'num_filters': 32}   \n4                 5                64   {'kernel_size': 5, 'num_filters': 64}   \n5                 5               128  {'kernel_size': 5, 'num_filters': 128}   \n6                 7                32   {'kernel_size': 7, 'num_filters': 32}   \n7                 7                64   {'kernel_size': 7, 'num_filters': 64}   \n8                 7               128  {'kernel_size': 7, 'num_filters': 128}   \n\n   split0_test_score  split1_test_score  mean_test_score  std_test_score  \\\n0           0.824742           0.770833         0.797788        0.026954   \n1           0.886598           0.854167         0.870382        0.016216   \n2           0.855670           0.833333         0.844502        0.011168   \n3           0.752577           0.802083         0.777330        0.024753   \n4           0.762887           0.875000         0.818943        0.056057   \n5           0.835052           0.875000         0.855026        0.019974   \n6           0.597938           0.729167         0.663552        0.065614   \n7           0.762887           0.822917         0.792902        0.030015   \n8           0.804124           0.770833         0.787479        0.016645   \n\n   rank_test_score  \n0                5  \n1                1  \n2                3  \n3                8  \n4                4  \n5                2  \n6                9  \n7                6  \n8                7  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mean_fit_time</th>\n      <th>std_fit_time</th>\n      <th>mean_score_time</th>\n      <th>std_score_time</th>\n      <th>param_kernel_size</th>\n      <th>param_num_filters</th>\n      <th>params</th>\n      <th>split0_test_score</th>\n      <th>split1_test_score</th>\n      <th>mean_test_score</th>\n      <th>std_test_score</th>\n      <th>rank_test_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.882793</td>\n      <td>0.454283</td>\n      <td>0.298693</td>\n      <td>0.015253</td>\n      <td>3</td>\n      <td>32</td>\n      <td>{'kernel_size': 3, 'num_filters': 32}</td>\n      <td>0.824742</td>\n      <td>0.770833</td>\n      <td>0.797788</td>\n      <td>0.026954</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.641088</td>\n      <td>0.024222</td>\n      <td>0.244344</td>\n      <td>0.042319</td>\n      <td>3</td>\n      <td>64</td>\n      <td>{'kernel_size': 3, 'num_filters': 64}</td>\n      <td>0.886598</td>\n      <td>0.854167</td>\n      <td>0.870382</td>\n      <td>0.016216</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.414505</td>\n      <td>0.022797</td>\n      <td>0.277051</td>\n      <td>0.042893</td>\n      <td>3</td>\n      <td>128</td>\n      <td>{'kernel_size': 3, 'num_filters': 128}</td>\n      <td>0.855670</td>\n      <td>0.833333</td>\n      <td>0.844502</td>\n      <td>0.011168</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.372716</td>\n      <td>0.237321</td>\n      <td>0.282250</td>\n      <td>0.001934</td>\n      <td>5</td>\n      <td>32</td>\n      <td>{'kernel_size': 5, 'num_filters': 32}</td>\n      <td>0.752577</td>\n      <td>0.802083</td>\n      <td>0.777330</td>\n      <td>0.024753</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1.531836</td>\n      <td>0.135869</td>\n      <td>0.266720</td>\n      <td>0.014222</td>\n      <td>5</td>\n      <td>64</td>\n      <td>{'kernel_size': 5, 'num_filters': 64}</td>\n      <td>0.762887</td>\n      <td>0.875000</td>\n      <td>0.818943</td>\n      <td>0.056057</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>1.619876</td>\n      <td>0.008948</td>\n      <td>0.271923</td>\n      <td>0.003191</td>\n      <td>5</td>\n      <td>128</td>\n      <td>{'kernel_size': 5, 'num_filters': 128}</td>\n      <td>0.835052</td>\n      <td>0.875000</td>\n      <td>0.855026</td>\n      <td>0.019974</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>1.255499</td>\n      <td>0.045334</td>\n      <td>0.298526</td>\n      <td>0.054369</td>\n      <td>7</td>\n      <td>32</td>\n      <td>{'kernel_size': 7, 'num_filters': 32}</td>\n      <td>0.597938</td>\n      <td>0.729167</td>\n      <td>0.663552</td>\n      <td>0.065614</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>1.654373</td>\n      <td>0.025872</td>\n      <td>0.193702</td>\n      <td>0.041367</td>\n      <td>7</td>\n      <td>64</td>\n      <td>{'kernel_size': 7, 'num_filters': 64}</td>\n      <td>0.762887</td>\n      <td>0.822917</td>\n      <td>0.792902</td>\n      <td>0.030015</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>1.777422</td>\n      <td>0.034260</td>\n      <td>0.296066</td>\n      <td>0.010772</td>\n      <td>7</td>\n      <td>128</td>\n      <td>{'kernel_size': 7, 'num_filters': 128}</td>\n      <td>0.804124</td>\n      <td>0.770833</td>\n      <td>0.787479</td>\n      <td>0.016645</td>\n      <td>7</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_result.best_params_\n",
    "pd.DataFrame(search.cv_results_)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "import tensorflow as tf\n",
    "from keras.layers import TextVectorization\n",
    "from keras.layers import Embedding\n",
    "from keras import layers\n",
    "\n",
    "max_words = 30 # Max number of words in a sentence\n",
    "\n",
    "raw_inputs = X_train_embedded\n",
    "padded_inputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "    X_train_embedded,\n",
    "    maxlen=max_words,\n",
    "    padding=\"pre\",\n",
    "    truncating=\"pre\",\n",
    "    dtype=\"float32\",\n",
    ")\n",
    "\n",
    "# Affichage des scores moyens par pli\n",
    "print('---------------------------------------------------------------------')\n",
    "print('Scores par pli')\n",
    "for i in range(0, len(acc_per_fold)):\n",
    "  print('---------------------------------------------------------------------')\n",
    "  print(f'> Pli {i+1} - Loss: {loss_per_fold[i]:.2f}',\n",
    "        f'- Accuracy: {acc_per_fold[i]:.2f}%')\n",
    "print('---------------------------------------------------------------------')\n",
    "print('Scores moyens pour tous les plis :')\n",
    "print(f'> Accuracy: {np.mean(acc_per_fold):.2f}',\n",
    "      f'(+- {np.std(acc_per_fold):.2f})')\n",
    "print(f'> Loss: {np.mean(loss_per_fold):.2f}')\n",
    "print('---------------------------------------------------------------------')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "accuracy_data = []\n",
    "loss_data = []\n",
    "for i, h in enumerate(histories):\n",
    "  acc = h.history['acc']\n",
    "  val_acc = h.history['val_acc']\n",
    "  loss = h.history['loss']\n",
    "  val_loss = h.history['val_loss']\n",
    "  for j in range(len(acc)):\n",
    "    accuracy_data.append([i+1, j+1, acc[j], 'Entraînement'])\n",
    "    accuracy_data.append([i+1, j+1, val_acc[j], 'Validation'])\n",
    "    loss_data.append([i+1, j+1, loss[j], 'Entraînement'])\n",
    "    loss_data.append([i+1, j+1, val_loss[j], 'Validation'])\n",
    "\n",
    "acc_df = pd.DataFrame(accuracy_data,\n",
    "                      columns=['Pli', 'Epoch', 'Accuracy', 'Données'])\n",
    "sns.relplot(data=acc_df, x='Epoch', y='Accuracy', hue='Pli', style='Données',\n",
    "            kind='line')\n",
    "\n",
    "loss_df = pd.DataFrame(loss_data, columns=['Pli', 'Epoch', 'Perte', 'Données'])\n",
    "sns.relplot(data=loss_df, x='Epoch', y='Perte', hue='Pli', style='Données',\n",
    "            kind='line')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Use party one to implement a CNN"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Tes with matrix embedding based solely on my vocab or on the whole spacy vocab"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "TODO : Once data has been generated, apply vizualization techniques found in partie 1 to it !"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
